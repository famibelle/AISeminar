{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5932077",
   "metadata": {},
   "source": [
    "# YOLO Video Object Detection Lab\n",
    "\n",
    "Ce notebook d√©montre comment utiliser YOLO (You Only Look Once) pour la d√©tection d'objets dans une vid√©o.\n",
    "\n",
    "## Objectifs:\n",
    "- Charger un mod√®le YOLO pr√©-entra√Æn√©\n",
    "- Traiter une vid√©o image par image\n",
    "- D√©tecter et annoter les objets\n",
    "- Sauvegarder la vid√©o annot√©e\n",
    "\n",
    "## Pr√©requis:\n",
    "- Python 3.8+\n",
    "- OpenCV\n",
    "- Ultralytics YOLO\n",
    "- Numpy\n",
    "- Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da5b400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\medhi\\SourceCode\\AISeminar\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\medhi\\SourceCode\\AISeminar\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\medhi\\SourceCode\\AISeminar\\.venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Installation pr√©alable d'OpenCV (optionnel - la cellule 6 force l'installation)\n",
    "%pip install opencv-python --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc4a67",
   "metadata": {},
   "source": [
    "## 1. Installation des d√©pendances\n",
    "\n",
    "Installez les biblioth√®ques n√©cessaires si elles ne sont pas d√©j√† pr√©sentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2c8b8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\medhi\\SourceCode\\AISeminar\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\medhi\\SourceCode\\AISeminar\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\medhi\\SourceCode\\AISeminar\\.venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Installation group√©e des d√©pendances (optionnel)\n",
    "%pip install ultralytics opencv-python matplotlib numpy pillow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76b879c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\medhi\\sourcecode\\aiseminar\\.venv\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\medhi\\sourcecode\\aiseminar\\.venv\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\medhi\\sourcecode\\aiseminar\\.venv\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\medhi\\sourcecode\\aiseminar\\.venv\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\medhi\\sourcecode\\aiseminar\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\medhi\\sourcecode\\aiseminar\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\medhi\\sourcecode\\aiseminar\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\medhi\\sourcecode\\aiseminar\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\medhi\\sourcecode\\aiseminar\\.venv\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\medhi\\sourcecode\\aiseminar\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\medhi\\sourcecode\\aiseminar\\.venv\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\medhi\\sourcecode\\aiseminar\\.venv\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\medhi\\sourcecode\\aiseminar\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\medhi\\sourcecode\\aiseminar\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\medhi\\SourceCode\\AISeminar\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\medhi\\SourceCode\\AISeminar\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\medhi\\SourceCode\\AISeminar\\.venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Installation PyTorch avec support CUDA (si vous avez un GPU NVIDIA)\n",
    "# D√©commentez la ligne suivante si vous voulez forcer l'installation de PyTorch avec CUDA\n",
    "%pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "689ef49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéÆ D√©tection de GPU et installation de PyTorch avec CUDA...\n",
      "üöÄ Installation de PyTorch avec support CUDA...\n",
      "   Cette op√©ration peut prendre quelques minutes...\n",
      "‚ö†Ô∏è D√©sinstallation de la version CPU de PyTorch...\n",
      "üì¶ Installation de PyTorch avec CUDA 12.1...\n",
      "üì¶ Installation de PyTorch avec CUDA 12.1...\n",
      "‚ùå Erreur lors de l'installation: WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\medhi\\SourceCode\\AISeminar\\.venv\\Lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement torch (from versions: none)\n",
      "ERROR: No matching distribution found for torch\n",
      "\n",
      "\n",
      "üíª Utilisation du CPU. Le traitement sera plus lent mais fonctionnel.\n",
      "‚ùå Erreur lors de l'installation: WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\medhi\\SourceCode\\AISeminar\\.venv\\Lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement torch (from versions: none)\n",
      "ERROR: No matching distribution found for torch\n",
      "\n",
      "\n",
      "üíª Utilisation du CPU. Le traitement sera plus lent mais fonctionnel.\n"
     ]
    }
   ],
   "source": [
    "# Installation de PyTorch avec support CUDA pour GPU NVIDIA\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_pytorch_cuda():\n",
    "    \"\"\"Installe PyTorch avec support CUDA pour utiliser le GPU.\"\"\"\n",
    "    print(\"üöÄ Installation de PyTorch avec support CUDA...\")\n",
    "    print(\"   Cette op√©ration peut prendre quelques minutes...\")\n",
    "    \n",
    "    # Commande pour installer PyTorch avec CUDA (version stable)\n",
    "    cmd = [\n",
    "        sys.executable, \"-m\", \"pip\", \"install\", \n",
    "        \"torch\", \"torchvision\", \"torchaudio\", \n",
    "        \"--index-url\", \"https://download.pytorch.org/whl/cu121\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # D√©sinstaller l'ancienne version CPU\n",
    "        print(\"‚ö†Ô∏è D√©sinstallation de la version CPU de PyTorch...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\", \"torch\", \"torchvision\", \"torchaudio\", \"-y\"], \n",
    "                            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        \n",
    "        # Installer la nouvelle version CUDA\n",
    "        print(\"üì¶ Installation de PyTorch avec CUDA 12.1...\")\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"‚úÖ PyTorch avec CUDA install√© avec succ√®s!\")\n",
    "            \n",
    "            # V√©rifier l'installation\n",
    "            import torch\n",
    "            print(f\"üîß PyTorch version: {torch.__version__}\")\n",
    "            print(f\"üéØ CUDA disponible: {'‚úÖ Oui' if torch.cuda.is_available() else '‚ùå Non'}\")\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                print(f\"üìä Version CUDA: {torch.version.cuda}\")\n",
    "                print(f\"üéÆ GPU d√©tect√©: {torch.cuda.get_device_name(0)}\")\n",
    "                print(f\"üíæ M√©moire GPU: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f} GB\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è CUDA non disponible apr√®s installation. V√©rifiez vos drivers NVIDIA.\")\n",
    "                return False\n",
    "        else:\n",
    "            print(f\"‚ùå Erreur lors de l'installation: {result.stderr}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur: {e}\")\n",
    "        return False\n",
    "\n",
    "# Lancer l'installation\n",
    "print(\"üéÆ D√©tection de GPU et installation de PyTorch avec CUDA...\")\n",
    "success = install_pytorch_cuda()\n",
    "\n",
    "if success:\n",
    "    print(\"\\nüöÄ Votre GPU est maintenant pr√™t pour YOLO!\")\n",
    "    print(\"   Red√©marrez le kernel puis relancez la cellule de v√©rification GPU.\")\n",
    "else:\n",
    "    print(\"\\nüíª Utilisation du CPU. Le traitement sera plus lent mais fonctionnel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b31e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Installation PyTorch CUDA via pip standard\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_pytorch_cuda_alternative():\n",
    "    \"\"\"Installation alternative de PyTorch avec CUDA.\"\"\"\n",
    "    print(\"üîÑ Installation alternative de PyTorch avec CUDA...\")\n",
    "    \n",
    "    try:\n",
    "        # M√©thode 1: Pip standard avec CUDA\n",
    "        print(\"üì¶ Tentative d'installation via pip standard...\")\n",
    "        cmd1 = [sys.executable, \"-m\", \"pip\", \"install\", \"torch\", \"torchvision\", \"torchaudio\", \"--upgrade\"]\n",
    "        result1 = subprocess.run(cmd1, capture_output=True, text=True)\n",
    "        \n",
    "        if result1.returncode == 0:\n",
    "            # V√©rifier si CUDA est disponible\n",
    "            import torch\n",
    "            print(f\"‚úÖ PyTorch install√©: {torch.__version__}\")\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                print(f\"üéØ CUDA disponible: ‚úÖ Oui\")\n",
    "                print(f\"üìä Version CUDA: {torch.version.cuda}\")\n",
    "                print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è PyTorch install√© mais CUDA non disponible\")\n",
    "                print(\"   Cela peut √™tre normal si votre GPU n'est pas compatible CUDA\")\n",
    "                return False\n",
    "        else:\n",
    "            print(f\"‚ùå Erreur pip standard: {result1.stderr}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur: {e}\")\n",
    "        return False\n",
    "\n",
    "# V√©rification actuelle de PyTorch\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"üîç PyTorch actuel: {torch.__version__}\")\n",
    "    print(f\"üéØ CUDA disponible: {'‚úÖ Oui' if torch.cuda.is_available() else '‚ùå Non'}\")\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"\\nüîÑ Tentative d'installation avec support CUDA...\")\n",
    "        install_pytorch_cuda_alternative()\n",
    "    else:\n",
    "        print(\"‚úÖ CUDA d√©j√† disponible!\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è PyTorch non trouv√©, installation en cours...\")\n",
    "    install_pytorch_cuda_alternative()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b07bc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéÆ V√©rification GPU NVIDIA rapide...\n",
      "üîç D√©tection rapide GPU NVIDIA...\n",
      "‚úÖ GPU NVIDIA trouv√©e: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "   üíæ M√©moire: 8188 MB (8.0 GB)\n",
      "   üîß Driver: 581.15\n",
      "‚ùå PyTorch non install√©\n",
      "\n",
      "üîÑ GPU NVIDIA d√©tect√©e mais PyTorch CUDA non fonctionnel\n",
      "\n",
      "üöÄ Installation PyTorch CUDA...\n",
      "üì¶ Installation en cours (cela peut prendre 1-2 minutes)...\n",
      "\n",
      "üöÄ Installation PyTorch CUDA...\n",
      "üì¶ Installation en cours (cela peut prendre 1-2 minutes)...\n",
      "‚è±Ô∏è Installation trop longue (timeout 5min)\n",
      "‚ö†Ô∏è Installation √©chou√©e, continuer avec CPU\n",
      "\n",
      "‚úÖ V√©rification termin√©e en quelques secondes!\n",
      "‚è±Ô∏è Installation trop longue (timeout 5min)\n",
      "‚ö†Ô∏è Installation √©chou√©e, continuer avec CPU\n",
      "\n",
      "‚úÖ V√©rification termin√©e en quelques secondes!\n"
     ]
    }
   ],
   "source": [
    "# D√©tection GPU NVIDIA rapide et installation PyTorch CUDA optimis√©e\n",
    "import subprocess\n",
    "import sys\n",
    "import re\n",
    "\n",
    "def quick_detect_nvidia():\n",
    "    \"\"\"D√©tection rapide de GPU NVIDIA avec timeout court.\"\"\"\n",
    "    try:\n",
    "        print(\"üîç D√©tection rapide GPU NVIDIA...\")\n",
    "        \n",
    "        # Commande courte pour juste v√©rifier la pr√©sence GPU\n",
    "        result = subprocess.run(['nvidia-smi.exe', '--query-gpu=name,memory.total,driver_version', '--format=csv,noheader,nounits'], \n",
    "                              capture_output=True, text=True, timeout=3)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            lines = result.stdout.strip().split('\\n')\n",
    "            if lines and lines[0]:\n",
    "                # Parsing simple de la premi√®re ligne\n",
    "                parts = lines[0].split(', ')\n",
    "                if len(parts) >= 3:\n",
    "                    gpu_name = parts[0].strip()\n",
    "                    memory_mb = int(parts[1].strip())\n",
    "                    driver_version = parts[2].strip()\n",
    "                    \n",
    "                    print(f\"‚úÖ GPU NVIDIA trouv√©e: {gpu_name}\")\n",
    "                    print(f\"   üíæ M√©moire: {memory_mb} MB ({memory_mb/1024:.1f} GB)\")\n",
    "                    print(f\"   üîß Driver: {driver_version}\")\n",
    "                    return True, gpu_name, memory_mb\n",
    "        \n",
    "        return False, None, 0\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"‚è±Ô∏è Timeout nvidia-smi (3s)\")\n",
    "        return False, None, 0\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur d√©tection: {e}\")\n",
    "        return False, None, 0\n",
    "\n",
    "def check_pytorch_cuda_status():\n",
    "    \"\"\"V√©rification rapide du statut CUDA de PyTorch.\"\"\"\n",
    "    try:\n",
    "        import torch\n",
    "        cuda_available = torch.cuda.is_available()\n",
    "        \n",
    "        print(f\"üîß PyTorch: {torch.__version__}\")\n",
    "        print(f\"üéØ CUDA: {'‚úÖ Activ√©' if cuda_available else '‚ùå D√©sactiv√©'}\")\n",
    "        \n",
    "        if cuda_available:\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "            print(f\"üéÆ GPU PyTorch: {gpu_name}\")\n",
    "            print(f\"üíæ M√©moire GPU: {gpu_memory:.1f} GB\")\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"‚ùå PyTorch non install√©\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur PyTorch: {e}\")\n",
    "        return False\n",
    "\n",
    "def install_pytorch_cuda_fast():\n",
    "    \"\"\"Installation rapide de PyTorch avec CUDA.\"\"\"\n",
    "    print(\"\\nüöÄ Installation PyTorch CUDA...\")\n",
    "    \n",
    "    try:\n",
    "        # Installation directe sans d√©sinstallation (plus rapide)\n",
    "        cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \n",
    "               \"torch\", \"torchvision\", \"torchaudio\", \"--index-url\", \"https://download.pytorch.org/whl/cu118\"]\n",
    "        \n",
    "        print(\"üì¶ Installation en cours (cela peut prendre 1-2 minutes)...\")\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)  # 5 min max\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"‚úÖ Installation termin√©e!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Erreur: {result.stderr[:200]}...\")  # Afficher seulement le d√©but de l'erreur\n",
    "            return False\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"‚è±Ô∏è Installation trop longue (timeout 5min)\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur installation: {e}\")\n",
    "        return False\n",
    "\n",
    "# === EXECUTION RAPIDE ===\n",
    "print(\"üéÆ V√©rification GPU NVIDIA rapide...\")\n",
    "\n",
    "# 1. D√©tection GPU rapide\n",
    "nvidia_found, gpu_name, gpu_memory = quick_detect_nvidia()\n",
    "\n",
    "# 2. V√©rification PyTorch CUDA\n",
    "pytorch_cuda_ok = check_pytorch_cuda_status()\n",
    "\n",
    "# 3. D√©cision et action\n",
    "if nvidia_found and not pytorch_cuda_ok:\n",
    "    print(\"\\nüîÑ GPU NVIDIA d√©tect√©e mais PyTorch CUDA non fonctionnel\")\n",
    "    \n",
    "    user_choice = input(\"Voulez-vous installer PyTorch avec CUDA ? (y/N): \").strip().lower()\n",
    "    if user_choice in ['y', 'yes', 'oui', 'o']:\n",
    "        success = install_pytorch_cuda_fast()\n",
    "        if success:\n",
    "            print(\"‚úÖ Red√©marrez le kernel pour activer CUDA!\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Installation √©chou√©e, continuer avec CPU\")\n",
    "    else:\n",
    "        print(\"üíª Continuer avec CPU\")\n",
    "        \n",
    "elif nvidia_found and pytorch_cuda_ok:\n",
    "    print(\"\\nüöÄ GPU NVIDIA et PyTorch CUDA op√©rationnels!\")\n",
    "    \n",
    "elif nvidia_found and not pytorch_cuda_ok:\n",
    "    print(\"\\n‚ö†Ô∏è GPU NVIDIA trouv√©e mais PyTorch CUDA non configur√©\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nüíª Aucune GPU NVIDIA d√©tect√©e, utilisation CPU\")\n",
    "\n",
    "print(f\"\\n‚úÖ V√©rification termin√©e en quelques secondes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279f5da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation et v√©rification d'OpenCV\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_and_import(package, import_name=None):\n",
    "    \"\"\"Installe un package et v√©rifie l'import.\"\"\"\n",
    "    if import_name is None:\n",
    "        import_name = package\n",
    "    \n",
    "    try:\n",
    "        __import__(import_name)\n",
    "        print(f\"‚úÖ {package} d√©j√† disponible\")\n",
    "    except ImportError:\n",
    "        print(f\"‚ö†Ô∏è Installation de {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"])\n",
    "        try:\n",
    "            __import__(import_name)\n",
    "            print(f\"‚úÖ {package} install√© et import√© avec succ√®s\")\n",
    "        except ImportError:\n",
    "            print(f\"‚ùå Erreur lors de l'import de {package}\")\n",
    "            raise\n",
    "\n",
    "# Installation forc√©e des d√©pendances critiques\n",
    "install_and_import(\"opencv-python\", \"cv2\")\n",
    "install_and_import(\"numpy\", \"numpy\")\n",
    "install_and_import(\"matplotlib\", \"matplotlib\")\n",
    "\n",
    "# Maintenant on peut importer normalement\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "# V√©rification pr√©liminaire de PyTorch et CUDA\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA disponible: {'‚úÖ Oui' if torch.cuda.is_available() else '‚ùå Non'}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"Version CUDA: {torch.version.cuda}\")\n",
    "        print(f\"GPU d√©tect√©: {torch.cuda.get_device_name(0)}\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è PyTorch non trouv√©, installation en cours...\")\n",
    "    install_and_import(\"torch\", \"torch\")\n",
    "    install_and_import(\"torchvision\", \"torchvision\") \n",
    "    install_and_import(\"torchaudio\", \"torchaudio\")\n",
    "\n",
    "print(\"‚úÖ Toutes les d√©pendances sont install√©es avec succ√®s!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fb4c9e",
   "metadata": {},
   "source": [
    "## 1.5. Configuration GPU et optimisation\n",
    "\n",
    "V√©rification et configuration du GPU pour acc√©l√©rer les traitements YOLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification et configuration du GPU\n",
    "import torch\n",
    "\n",
    "# V√©rifier la disponibilit√© du GPU\n",
    "def check_gpu_availability():\n",
    "    \"\"\"V√©rifie la disponibilit√© du GPU et affiche les informations.\"\"\"\n",
    "    print(\"üîç V√©rification de l'environnement GPU...\")\n",
    "    \n",
    "    # V√©rifier CUDA\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    print(f\"CUDA disponible: {'‚úÖ Oui' if cuda_available else '‚ùå Non'}\")\n",
    "    \n",
    "    if cuda_available:\n",
    "        # Informations d√©taill√©es sur le GPU\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        print(f\"Nombre de GPU(s): {gpu_count}\")\n",
    "        \n",
    "        for i in range(gpu_count):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)\n",
    "            print(f\"  GPU {i}: {gpu_name}\")\n",
    "            print(f\"  M√©moire totale: {gpu_memory:.1f} GB\")\n",
    "            \n",
    "        # M√©moire disponible\n",
    "        current_device = torch.cuda.current_device()\n",
    "        memory_allocated = torch.cuda.memory_allocated(current_device) / (1024**3)\n",
    "        memory_reserved = torch.cuda.memory_reserved(current_device) / (1024**3)\n",
    "        print(f\"M√©moire allou√©e: {memory_allocated:.2f} GB\")\n",
    "        print(f\"M√©moire r√©serv√©e: {memory_reserved:.2f} GB\")\n",
    "        \n",
    "        # Test simple\n",
    "        try:\n",
    "            test_tensor = torch.randn(1000, 1000).cuda()\n",
    "            print(\"‚úÖ Test GPU r√©ussi!\")\n",
    "            del test_tensor\n",
    "            torch.cuda.empty_cache()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur lors du test GPU: {e}\")\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è GPU non disponible. Le traitement utilisera le CPU.\")\n",
    "        print(\"   Pour utiliser le GPU, assurez-vous d'avoir:\")\n",
    "        print(\"   - Un GPU NVIDIA compatible CUDA\")\n",
    "        print(\"   - Les drivers NVIDIA √† jour\")\n",
    "        print(\"   - PyTorch avec support CUDA install√©\")\n",
    "        return False\n",
    "\n",
    "# V√©rifier le GPU\n",
    "gpu_available = check_gpu_availability()\n",
    "\n",
    "# Configuration du device pour YOLO\n",
    "if gpu_available:\n",
    "    DEVICE = 'cuda'\n",
    "    print(f\"\\nüöÄ Configuration: GPU activ√© (device: {DEVICE})\")\n",
    "    # Optimisations GPU\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"‚úÖ Optimisations GPU activ√©es\")\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "    print(f\"\\nüíª Configuration: CPU utilis√© (device: {DEVICE})\")\n",
    "\n",
    "print(f\"Device YOLO: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860738f3",
   "metadata": {},
   "source": [
    "## 2. Configuration et chargement du mod√®le YOLO\n",
    "\n",
    "Nous utiliserons YOLOv8 d'Ultralytics, qui est l'une des versions les plus r√©centes et performantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c4b467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du mod√®le YOLO pr√©-entra√Æn√© avec GPU\n",
    "# Vous pouvez choisir diff√©rentes tailles de mod√®le: yolov8n, yolov8s, yolov8m, yolov8l, yolov8x\n",
    "# 'n' = nano (plus rapide), 'x' = extra large (plus pr√©cis)\n",
    "\n",
    "model_name = \"yolov8n.pt\"  # Mod√®le nano pour la rapidit√©\n",
    "model = YOLO(model_name)\n",
    "\n",
    "# Configuration du device (GPU si disponible)\n",
    "try:\n",
    "    model.to(DEVICE)\n",
    "    print(f\"‚úÖ Mod√®le {model_name} charg√© avec succ√®s sur {DEVICE.upper()}!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erreur lors du chargement sur {DEVICE}: {e}\")\n",
    "    DEVICE = 'cpu'\n",
    "    model.to(DEVICE)\n",
    "    print(f\"üîÑ Mod√®le charg√© sur CPU √† la place\")\n",
    "\n",
    "print(f\"Classes d√©tectables: {len(model.names)} classes\")\n",
    "print(f\"Device utilis√©: {DEVICE}\")\n",
    "\n",
    "# Affichage des premi√®res classes\n",
    "for i, class_name in enumerate(list(model.names.values())[:10]):\n",
    "    print(f\"{i}: {class_name}\")\n",
    "print(\"...\")\n",
    "\n",
    "# Optimisations sp√©cifiques GPU\n",
    "if DEVICE == 'cuda':\n",
    "    print(\"\\nüöÄ Optimisations GPU activ√©es:\")\n",
    "    print(\"   - Fusion des op√©rations\")\n",
    "    print(\"   - Optimisation m√©moire\")\n",
    "    print(\"   - Traitement par batch optimis√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6983fe6",
   "metadata": {},
   "source": [
    "## 3. Configuration des param√®tres de d√©tection\n",
    "\n",
    "D√©finissez les param√®tres pour la d√©tection d'objets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e03075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param√®tres de d√©tection\n",
    "CONFIDENCE_THRESHOLD = 0.5  # Seuil de confiance minimum\n",
    "IOU_THRESHOLD = 0.5        # Seuil IoU pour la suppression non-maximale\n",
    "\n",
    "# Classes √† d√©tecter (None = toutes les classes, ou liste des indices de classes)\n",
    "CLASSES_TO_DETECT = None  # Exemple: [0, 1, 2] pour person, bicycle, car\n",
    "\n",
    "# Couleurs pour les bounding boxes (BGR format)\n",
    "COLORS = {\n",
    "    'person': (255, 0, 0),      # Bleu\n",
    "    'car': (0, 255, 0),         # Vert\n",
    "    'truck': (0, 0, 255),       # Rouge\n",
    "    'bicycle': (255, 255, 0),   # Cyan\n",
    "    'motorcycle': (255, 0, 255), # Magenta\n",
    "    'default': (0, 255, 255)    # Jaune\n",
    "}\n",
    "\n",
    "print(\"Param√®tres de d√©tection configur√©s:\")\n",
    "print(f\"Seuil de confiance: {CONFIDENCE_THRESHOLD}\")\n",
    "print(f\"Seuil IoU: {IOU_THRESHOLD}\")\n",
    "print(f\"Classes √† d√©tecter: {'Toutes' if CLASSES_TO_DETECT is None else CLASSES_TO_DETECT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ca37b",
   "metadata": {},
   "source": [
    "## 4. Chargement et information sur la vid√©o d'entr√©e\n",
    "\n",
    "**Modifiez le chemin ci-dessous pour pointer vers votre vid√©o.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce318e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGEZ CE CHEMIN VERS VOTRE VID√âO\n",
    "VIDEO_PATH = \"Labs\\Media\\HitachiAstemoWinterTest_SmartBrakeMovie2022.mp4\"  # Remplacez par le chemin de votre vid√©o\n",
    "\n",
    "# V√©rification de l'existence du fichier\n",
    "if not os.path.exists(VIDEO_PATH):\n",
    "    print(f\"‚ùå Erreur: Le fichier vid√©o '{VIDEO_PATH}' n'existe pas.\")\n",
    "    print(\"Veuillez modifier VIDEO_PATH avec le chemin correct de votre vid√©o.\")\n",
    "    VIDEO_PATH = None\n",
    "else:\n",
    "    # Ouverture de la vid√©o pour obtenir des informations\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    \n",
    "    if cap.isOpened():\n",
    "        # Informations sur la vid√©o\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = total_frames / fps\n",
    "        \n",
    "        print(f\"‚úÖ Vid√©o charg√©e avec succ√®s!\")\n",
    "        print(f\"üìÅ Chemin: {VIDEO_PATH}\")\n",
    "        print(f\"üìê R√©solution: {width}x{height}\")\n",
    "        print(f\"üé¨ FPS: {fps}\")\n",
    "        print(f\"üéûÔ∏è Nombre total d'images: {total_frames}\")\n",
    "        print(f\"‚è±Ô∏è Dur√©e: {duration:.2f} secondes\")\n",
    "        \n",
    "        cap.release()\n",
    "    else:\n",
    "        print(f\"‚ùå Erreur: Impossible d'ouvrir la vid√©o '{VIDEO_PATH}'\")\n",
    "        VIDEO_PATH = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01efc92b",
   "metadata": {},
   "source": [
    "## 5. Fonctions utilitaires pour la d√©tection et l'annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62e8aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_for_class(class_name):\n",
    "    \"\"\"Retourne une couleur pour une classe donn√©e.\"\"\"\n",
    "    return COLORS.get(class_name, COLORS['default'])\n",
    "\n",
    "def draw_bounding_box(image, bbox, class_name, confidence):\n",
    "    \"\"\"Dessine une bounding box avec le nom de la classe et la confiance.\"\"\"\n",
    "    x1, y1, x2, y2 = map(int, bbox)\n",
    "    color = get_color_for_class(class_name)\n",
    "    \n",
    "    # Dessiner le rectangle\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "    \n",
    "    # Pr√©parer le texte\n",
    "    label = f\"{class_name}: {confidence:.2f}\"\n",
    "    \n",
    "    # Calculer la taille du texte\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.5\n",
    "    thickness = 1\n",
    "    (text_width, text_height), _ = cv2.getTextSize(label, font, font_scale, thickness)\n",
    "    \n",
    "    # Dessiner le fond du texte\n",
    "    cv2.rectangle(image, (x1, y1 - text_height - 10), (x1 + text_width, y1), color, -1)\n",
    "    \n",
    "    # Dessiner le texte\n",
    "    cv2.putText(image, label, (x1, y1 - 5), font, font_scale, (255, 255, 255), thickness)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def process_detections(results, image):\n",
    "    \"\"\"Traite les r√©sultats de d√©tection et annote l'image.\"\"\"\n",
    "    annotated_image = image.copy()\n",
    "    detection_count = 0\n",
    "    \n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        if boxes is not None:\n",
    "            for box in boxes:\n",
    "                # Extraire les informations\n",
    "                bbox = box.xyxy[0].cpu().numpy()  # [x1, y1, x2, y2]\n",
    "                confidence = box.conf[0].cpu().numpy()\n",
    "                class_id = int(box.cls[0].cpu().numpy())\n",
    "                class_name = model.names[class_id]\n",
    "                \n",
    "                # Filtrer par confiance\n",
    "                if confidence >= CONFIDENCE_THRESHOLD:\n",
    "                    # Filtrer par classes si sp√©cifi√©\n",
    "                    if CLASSES_TO_DETECT is None or class_id in CLASSES_TO_DETECT:\n",
    "                        annotated_image = draw_bounding_box(\n",
    "                            annotated_image, bbox, class_name, confidence\n",
    "                        )\n",
    "                        detection_count += 1\n",
    "    \n",
    "    return annotated_image, detection_count\n",
    "\n",
    "def optimize_gpu_settings():\n",
    "    \"\"\"Optimise les param√®tres GPU pour YOLO.\"\"\"\n",
    "    if DEVICE == 'cuda' and torch.cuda.is_available():\n",
    "        # Activer les optimisations CUDA\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        \n",
    "        # Nettoyer la m√©moire GPU\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        print(\"üöÄ Optimisations GPU activ√©es:\")\n",
    "        print(\"   - CUDNN benchmark: True\")\n",
    "        print(\"   - M√©moire GPU nettoy√©e\")\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        print(\"üíª Optimisations CPU activ√©es\")\n",
    "        return False\n",
    "\n",
    "def get_optimal_batch_size():\n",
    "    \"\"\"D√©termine la taille de batch optimale selon le device.\"\"\"\n",
    "    if DEVICE == 'cuda' and torch.cuda.is_available():\n",
    "        # Estimer selon la m√©moire GPU disponible\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "        if gpu_memory >= 8:\n",
    "            return 8  # GPU avec 8GB+ de VRAM\n",
    "        elif gpu_memory >= 4:\n",
    "            return 4  # GPU avec 4-8GB de VRAM\n",
    "        else:\n",
    "            return 2  # GPU avec moins de 4GB de VRAM\n",
    "    else:\n",
    "        return 1  # CPU\n",
    "\n",
    "# Appliquer les optimisations\n",
    "optimize_gpu_settings()\n",
    "OPTIMAL_BATCH_SIZE = get_optimal_batch_size()\n",
    "\n",
    "print(\"Fonctions utilitaires d√©finies avec succ√®s!\")\n",
    "print(f\"Device configur√©: {DEVICE}\")\n",
    "print(f\"Taille de batch optimale: {OPTIMAL_BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43003870",
   "metadata": {},
   "source": [
    "## 6. Test sur une image unique (optionnel)\n",
    "\n",
    "Testons d'abord la d√©tection sur la premi√®re image de la vid√©o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af1b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VIDEO_PATH is not None:\n",
    "    # Lire la premi√®re image de la vid√©o\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if ret:\n",
    "        print(\"Test de d√©tection sur la premi√®re image...\")\n",
    "        print(f\"Utilisation du device: {DEVICE}\")\n",
    "        \n",
    "        # Mesurer le temps de traitement\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Effectuer la d√©tection avec device sp√©cifi√©\n",
    "        results = model(frame, conf=CONFIDENCE_THRESHOLD, iou=IOU_THRESHOLD, device=DEVICE)\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        print(f\"‚è±Ô∏è Temps de traitement: {processing_time:.3f} secondes\")\n",
    "        \n",
    "        # Traiter les r√©sultats\n",
    "        annotated_frame, detections = process_detections(results, frame)\n",
    "        \n",
    "        print(f\"D√©tections trouv√©es: {detections}\")\n",
    "        \n",
    "        # Afficher l'image originale et annot√©e\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "        \n",
    "        # Image originale\n",
    "        ax1.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        ax1.set_title('Image Originale')\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        # Image annot√©e\n",
    "        ax2.imshow(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))\n",
    "        ax2.set_title(f'D√©tections YOLO ({detections} objets) - {DEVICE.upper()}')\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Nettoyer la m√©moire GPU si utilis√©e\n",
    "        if DEVICE == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "    else:\n",
    "        print(\"‚ùå Erreur: Impossible de lire la premi√®re image de la vid√©o.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Aucune vid√©o charg√©e. Veuillez sp√©cifier VIDEO_PATH.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e42c3e",
   "metadata": {},
   "source": [
    "## 7. Traitement complet de la vid√©o\n",
    "\n",
    "Maintenant, traitons toute la vid√©o et sauvegardons le r√©sultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03b0f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VIDEO_PATH is not None:\n",
    "    # Pr√©parer les chemins de sortie\n",
    "    input_path = Path(VIDEO_PATH)\n",
    "    output_path = input_path.parent / f\"{input_path.stem}_yolo_detected{input_path.suffix}\"\n",
    "    \n",
    "    print(f\"üé¨ Traitement de la vid√©o: {VIDEO_PATH}\")\n",
    "    print(f\"üíæ Sortie: {output_path}\")\n",
    "    print(f\"üîß Device utilis√©: {DEVICE.upper()}\")\n",
    "    \n",
    "    # Ouvrir la vid√©o d'entr√©e\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    \n",
    "    # Obtenir les propri√©t√©s de la vid√©o\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Configurer l'encodeur vid√©o de sortie\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))\n",
    "    \n",
    "    # Variables pour les statistiques\n",
    "    frame_count = 0\n",
    "    total_detections = 0\n",
    "    total_processing_time = 0\n",
    "    \n",
    "    # Configuration pour traitement par batch (GPU uniquement)\n",
    "    BATCH_SIZE = 4 if DEVICE == 'cuda' else 1\n",
    "    frame_batch = []\n",
    "    \n",
    "    print(f\"üì¶ Taille de batch: {BATCH_SIZE}\")\n",
    "    print(\"\\nüöÄ D√©but du traitement...\")\n",
    "    \n",
    "    import time\n",
    "    start_total_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                # Traiter le dernier batch s'il reste des images\n",
    "                if frame_batch:\n",
    "                    start_time = time.time()\n",
    "                    results = model(frame_batch, conf=CONFIDENCE_THRESHOLD, iou=IOU_THRESHOLD, device=DEVICE, verbose=False)\n",
    "                    processing_time = time.time() - start_time\n",
    "                    total_processing_time += processing_time\n",
    "                    \n",
    "                    for i, result in enumerate(results):\n",
    "                        annotated_frame, detections = process_detections([result], frame_batch[i])\n",
    "                        total_detections += detections\n",
    "                        out.write(annotated_frame)\n",
    "                        frame_count += 1\n",
    "                break\n",
    "            \n",
    "            frame_batch.append(frame)\n",
    "            \n",
    "            # Traiter par batch\n",
    "            if len(frame_batch) == BATCH_SIZE:\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Effectuer la d√©tection sur le batch\n",
    "                results = model(frame_batch, conf=CONFIDENCE_THRESHOLD, iou=IOU_THRESHOLD, device=DEVICE, verbose=False)\n",
    "                \n",
    "                processing_time = time.time() - start_time\n",
    "                total_processing_time += processing_time\n",
    "                \n",
    "                # Traiter les r√©sultats de chaque image du batch\n",
    "                for i, result in enumerate(results):\n",
    "                    annotated_frame, detections = process_detections([result], frame_batch[i])\n",
    "                    total_detections += detections\n",
    "                    out.write(annotated_frame)\n",
    "                    frame_count += 1\n",
    "                \n",
    "                # Vider le batch\n",
    "                frame_batch = []\n",
    "                \n",
    "                # Afficher le progr√®s\n",
    "                if frame_count % 30 == 0:  # Afficher toutes les 30 images\n",
    "                    progress = (frame_count / total_frames) * 100\n",
    "                    fps_current = 30 / processing_time if processing_time > 0 else 0\n",
    "                    print(f\"üìà Progr√®s: {progress:.1f}% ({frame_count}/{total_frames}) - \"\n",
    "                          f\"D√©tections: {detections} - Vitesse: {fps_current:.1f} FPS\")\n",
    "                \n",
    "                # Nettoyer la m√©moire GPU p√©riodiquement\n",
    "                if DEVICE == 'cuda' and frame_count % 100 == 0:\n",
    "                    torch.cuda.empty_cache()\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚ö†Ô∏è Traitement interrompu par l'utilisateur.\")\n",
    "    \n",
    "    finally:\n",
    "        # Lib√©rer les ressources\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        \n",
    "        # Nettoyer la m√©moire GPU\n",
    "        if DEVICE == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        total_time = time.time() - start_total_time\n",
    "        \n",
    "        print(\"\\n‚úÖ Traitement termin√©!\")\n",
    "        print(f\"üìä Statistiques:\")\n",
    "        print(f\"   - Images trait√©es: {frame_count}/{total_frames}\")\n",
    "        print(f\"   - Total d√©tections: {total_detections}\")\n",
    "        print(f\"   - Moyenne d√©tections/image: {total_detections/frame_count:.2f}\")\n",
    "        print(f\"   - Temps total: {total_time:.2f} secondes\")\n",
    "        print(f\"   - Temps de traitement IA: {total_processing_time:.2f} secondes\")\n",
    "        print(f\"   - Vitesse moyenne: {frame_count/total_time:.2f} FPS\")\n",
    "        print(f\"   - Acc√©l√©ration IA: {frame_count/total_processing_time:.2f}x temps r√©el\")\n",
    "        print(f\"   - Device utilis√©: {DEVICE.upper()}\")\n",
    "        print(f\"   - Fichier de sortie: {output_path}\")\n",
    "        \n",
    "        if os.path.exists(output_path):\n",
    "            file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB\n",
    "            print(f\"   - Taille du fichier: {file_size:.2f} MB\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Aucune vid√©o charg√©e. Veuillez sp√©cifier VIDEO_PATH dans la cellule 4.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93602d4d",
   "metadata": {},
   "source": [
    "## 7.5. Compression de la vid√©o de sortie\n",
    "\n",
    "Compressons la vid√©o pour r√©duire sa taille de fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e582396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_video(input_path, output_path, scale_factor=0.75, quality=23):\n",
    "    \"\"\"\n",
    "    Compresse une vid√©o en r√©duisant sa r√©solution et en optimisant la qualit√©.\n",
    "    \n",
    "    Args:\n",
    "        input_path: Chemin de la vid√©o d'entr√©e\n",
    "        output_path: Chemin de la vid√©o compress√©e\n",
    "        scale_factor: Facteur de redimensionnement (0.75 = 75% de la taille originale)\n",
    "        quality: Qualit√© de compression (18-28, plus bas = meilleure qualit√©)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ouvrir la vid√©o d'entr√©e\n",
    "        cap = cv2.VideoCapture(str(input_path))\n",
    "        \n",
    "        if not cap.isOpened():\n",
    "            print(f\"‚ùå Erreur: Impossible d'ouvrir {input_path}\")\n",
    "            return False\n",
    "        \n",
    "        # Propri√©t√©s de la vid√©o originale\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # Nouvelles dimensions\n",
    "        new_width = int(width * scale_factor)\n",
    "        new_height = int(height * scale_factor)\n",
    "        \n",
    "        print(f\"üé¨ Compression de la vid√©o:\")\n",
    "        print(f\"   R√©solution originale: {width}x{height}\")\n",
    "        print(f\"   Nouvelle r√©solution: {new_width}x{new_height}\")\n",
    "        print(f\"   Facteur de r√©duction: {scale_factor}\")\n",
    "        \n",
    "        # Configuration de l'encodeur avec compression H.264\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(str(output_path), fourcc, fps, (new_width, new_height))\n",
    "        \n",
    "        if not out.isOpened():\n",
    "            print(f\"‚ùå Erreur: Impossible de cr√©er {output_path}\")\n",
    "            cap.release()\n",
    "            return False\n",
    "        \n",
    "        frame_count = 0\n",
    "        print(\"\\\\nüöÄ D√©but de la compression...\")\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Redimensionner l'image\n",
    "            resized_frame = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "            # √âcrire l'image redimensionn√©e\n",
    "            out.write(resized_frame)\n",
    "            frame_count += 1\n",
    "            \n",
    "            # Afficher le progr√®s\n",
    "            if frame_count % 100 == 0:\n",
    "                progress = (frame_count / total_frames) * 100\n",
    "                print(f\"üìà Compression: {progress:.1f}% ({frame_count}/{total_frames})\")\n",
    "        \n",
    "        # Lib√©rer les ressources\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        \n",
    "        # Statistiques de compression\n",
    "        if os.path.exists(output_path):\n",
    "            original_size = os.path.getsize(input_path) / (1024 * 1024)  # MB\n",
    "            compressed_size = os.path.getsize(output_path) / (1024 * 1024)  # MB\n",
    "            compression_ratio = (1 - compressed_size / original_size) * 100\n",
    "            \n",
    "            print(f\"\\\\n‚úÖ Compression termin√©e!\")\n",
    "            print(f\"üìä Statistiques de compression:\")\n",
    "            print(f\"   - Taille originale: {original_size:.2f} MB\")\n",
    "            print(f\"   - Taille compress√©e: {compressed_size:.2f} MB\")\n",
    "            print(f\"   - R√©duction: {compression_ratio:.1f}%\")\n",
    "            print(f\"   - Fichier compress√©: {output_path}\")\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå Erreur: Le fichier compress√© n'a pas √©t√© cr√©√©\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors de la compression: {e}\")\n",
    "        return False\n",
    "\n",
    "# Compression de la vid√©o de sortie YOLO\n",
    "if VIDEO_PATH is not None:\n",
    "    input_path = Path(VIDEO_PATH)\n",
    "    yolo_output_path = input_path.parent / f\"{input_path.stem}_yolo_detected{input_path.suffix}\"\n",
    "    \n",
    "    if os.path.exists(yolo_output_path):\n",
    "        # Cr√©er le nom du fichier compress√©\n",
    "        compressed_output_path = input_path.parent / f\"{input_path.stem}_yolo_detected_compressed{input_path.suffix}\"\n",
    "        \n",
    "        # Param√®tres de compression\n",
    "        SCALE_FACTOR = 0.75  # R√©duire la r√©solution √† 75%\n",
    "        QUALITY = 23         # Qualit√© de compression (18-28)\n",
    "        \n",
    "        print(f\"üóúÔ∏è Compression de la vid√©o YOLO d√©tect√©e...\")\n",
    "        success = compress_video(yolo_output_path, compressed_output_path, SCALE_FACTOR, QUALITY)\n",
    "        \n",
    "        if success:\n",
    "            print(f\"\\\\nüéØ Vid√©o compress√©e disponible √†: {compressed_output_path}\")\n",
    "        else:\n",
    "            print(f\"\\\\n‚ö†Ô∏è √âchec de la compression\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Aucune vid√©o YOLO d√©tect√©e trouv√©e √† compresser\")\n",
    "        print(\"   Ex√©cutez d'abord la cellule de traitement complet de la vid√©o\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Aucune vid√©o source charg√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bddc52",
   "metadata": {},
   "source": [
    "## 7.6. Compression avanc√©e avec FFmpeg (optionnel)\n",
    "\n",
    "Utilisation de FFmpeg pour une compression plus efficace (si disponible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7abec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_video_ffmpeg(input_path, output_path, scale_factor=0.75, crf=23):\n",
    "    \"\"\"\n",
    "    Compresse une vid√©o avec FFmpeg pour une meilleure qualit√©/taille.\n",
    "    \n",
    "    Args:\n",
    "        input_path: Chemin de la vid√©o d'entr√©e\n",
    "        output_path: Chemin de la vid√©o compress√©e\n",
    "        scale_factor: Facteur de redimensionnement (0.75 = 75% de la taille)\n",
    "        crf: Constant Rate Factor (18-28, plus bas = meilleure qualit√©)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import subprocess\n",
    "        \n",
    "        # V√©rifier si FFmpeg est disponible\n",
    "        try:\n",
    "            result = subprocess.run(['ffmpeg', '-version'], \n",
    "                                  capture_output=True, text=True, timeout=5)\n",
    "            if result.returncode != 0:\n",
    "                raise FileNotFoundError\n",
    "        except (FileNotFoundError, subprocess.TimeoutExpired):\n",
    "            print(\"‚ö†Ô∏è FFmpeg n'est pas install√© ou disponible dans le PATH\")\n",
    "            print(\"   Utilisation de la compression OpenCV √† la place...\")\n",
    "            return compress_video(input_path, output_path, scale_factor)\n",
    "        \n",
    "        # Obtenir les dimensions originales\n",
    "        cap = cv2.VideoCapture(str(input_path))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        cap.release()\n",
    "        \n",
    "        # Nouvelles dimensions (multiples de 2 pour la compatibilit√©)\n",
    "        new_width = int((width * scale_factor) // 2) * 2\n",
    "        new_height = int((height * scale_factor) // 2) * 2\n",
    "        \n",
    "        print(f\"üé¨ Compression FFmpeg:\")\n",
    "        print(f\"   R√©solution: {width}x{height} ‚Üí {new_width}x{new_height}\")\n",
    "        print(f\"   CRF: {crf} (qualit√©)\")\n",
    "        \n",
    "        # Commande FFmpeg\n",
    "        cmd = [\n",
    "            'ffmpeg',\n",
    "            '-i', str(input_path),                    # Fichier d'entr√©e\n",
    "            '-vf', f'scale={new_width}:{new_height}', # Redimensionnement\n",
    "            '-c:v', 'libx264',                        # Codec H.264\n",
    "            '-crf', str(crf),                         # Qualit√©\n",
    "            '-preset', 'medium',                      # Vitesse d'encodage\n",
    "            '-c:a', 'aac',                           # Codec audio\n",
    "            '-b:a', '128k',                          # Bitrate audio\n",
    "            '-movflags', '+faststart',               # Optimisation streaming\n",
    "            '-y',                                    # Remplacer si existe\n",
    "            str(output_path)                         # Fichier de sortie\n",
    "        ]\n",
    "        \n",
    "        print(\"\\\\nüöÄ D√©but de la compression FFmpeg...\")\n",
    "        \n",
    "        # Ex√©cuter FFmpeg\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            # Statistiques\n",
    "            if os.path.exists(output_path):\n",
    "                original_size = os.path.getsize(input_path) / (1024 * 1024)\n",
    "                compressed_size = os.path.getsize(output_path) / (1024 * 1024)\n",
    "                compression_ratio = (1 - compressed_size / original_size) * 100\n",
    "                \n",
    "                print(f\"\\\\n‚úÖ Compression FFmpeg termin√©e!\")\n",
    "                print(f\"üìä Statistiques:\")\n",
    "                print(f\"   - Taille originale: {original_size:.2f} MB\")\n",
    "                print(f\"   - Taille compress√©e: {compressed_size:.2f} MB\")\n",
    "                print(f\"   - R√©duction: {compression_ratio:.1f}%\")\n",
    "                print(f\"   - Fichier: {output_path}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"‚ùå Erreur: Fichier de sortie non cr√©√©\")\n",
    "                return False\n",
    "        else:\n",
    "            print(f\"‚ùå Erreur FFmpeg: {result.stderr}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors de la compression FFmpeg: {e}\")\n",
    "        return False\n",
    "\n",
    "# Option de compression avanc√©e\n",
    "if VIDEO_PATH is not None:\n",
    "    input_path = Path(VIDEO_PATH)\n",
    "    yolo_output_path = input_path.parent / f\"{input_path.stem}_yolo_detected{input_path.suffix}\"\n",
    "    \n",
    "    if os.path.exists(yolo_output_path):\n",
    "        # Nom du fichier avec compression FFmpeg\n",
    "        ffmpeg_output_path = input_path.parent / f\"{input_path.stem}_yolo_detected_ffmpeg{input_path.suffix}\"\n",
    "        \n",
    "        # Param√®tres de compression avanc√©e\n",
    "        SCALE_FACTOR = 0.8   # R√©duction √† 80%\n",
    "        CRF = 23            # Qualit√© (18=excellent, 23=bon, 28=acceptable)\n",
    "        \n",
    "        print(\"üîß Options de compression disponibles:\")\n",
    "        print(\"1. Compression OpenCV (d√©j√† effectu√©e)\")\n",
    "        print(\"2. Compression FFmpeg (meilleure qualit√©/taille)\")\n",
    "        print(\"\\\\nEx√©cution de la compression FFmpeg...\")\n",
    "        \n",
    "        success = compress_video_ffmpeg(yolo_output_path, ffmpeg_output_path, SCALE_FACTOR, CRF)\n",
    "        \n",
    "        if success:\n",
    "            print(f\"\\\\nüéØ Vid√©o FFmpeg disponible √†: {ffmpeg_output_path}\")\n",
    "            \n",
    "            # Comparaison des tailles\n",
    "            original_size = os.path.getsize(yolo_output_path) / (1024 * 1024)\n",
    "            opencv_compressed = input_path.parent / f\"{input_path.stem}_yolo_detected_compressed{input_path.suffix}\"\n",
    "            ffmpeg_size = os.path.getsize(ffmpeg_output_path) / (1024 * 1024)\n",
    "            \n",
    "            print(f\"\\\\nüìä Comparaison des compressions:\")\n",
    "            print(f\"   - Vid√©o YOLO originale: {original_size:.2f} MB\")\n",
    "            if os.path.exists(opencv_compressed):\n",
    "                opencv_size = os.path.getsize(opencv_compressed) / (1024 * 1024)\n",
    "                print(f\"   - Compression OpenCV: {opencv_size:.2f} MB\")\n",
    "            print(f\"   - Compression FFmpeg: {ffmpeg_size:.2f} MB\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Aucune vid√©o YOLO d√©tect√©e trouv√©e pour compression FFmpeg\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Aucune vid√©o source charg√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b28e19",
   "metadata": {},
   "source": [
    "## 8. Analyse des r√©sultats (optionnel)\n",
    "\n",
    "Analysons quelques images de la vid√©o trait√©e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d2c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VIDEO_PATH is not None:\n",
    "    # Analyser quelques images al√©atoirement\n",
    "    output_path = Path(VIDEO_PATH).parent / f\"{Path(VIDEO_PATH).stem}_yolo_detected{Path(VIDEO_PATH).suffix}\"\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        cap = cv2.VideoCapture(str(output_path))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # S√©lectionner 4 images al√©atoirement\n",
    "        import random\n",
    "        random_frames = random.sample(range(0, total_frames), min(4, total_frames))\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, frame_num in enumerate(random_frames):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if ret:\n",
    "                axes[i].imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                axes[i].set_title(f'Image {frame_num + 1}/{total_frames}')\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        cap.release()\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle('√âchantillons de la vid√©o trait√©e avec YOLO', fontsize=16, y=1.02)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"‚ùå Le fichier de sortie {output_path} n'existe pas.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Aucune vid√©o charg√©e.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3c86df",
   "metadata": {},
   "source": [
    "## 9. Configuration avanc√©e (optionnel)\n",
    "\n",
    "Voici quelques param√®tres avanc√©s que vous pouvez modifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af310b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration avanc√©e GPU et performance\n",
    "print(\"üîß Configuration avanc√©e disponible:\")\n",
    "\n",
    "print(\"\\n1. Mod√®les YOLO disponibles:\")\n",
    "models = ['yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt', 'yolov8l.pt', 'yolov8x.pt']\n",
    "for model_name in models:\n",
    "    speed = \"Tr√®s rapide\" if 'n' in model_name else \"Rapide\" if 's' in model_name else \"√âquilibr√©\" if 'm' in model_name else \"Lent mais pr√©cis\" if 'l' in model_name else \"Tr√®s pr√©cis mais lent\"\n",
    "    print(f\"   - {model_name}: {speed}\")\n",
    "\n",
    "print(\"\\n2. Classes COCO (quelques exemples):\")\n",
    "common_classes = {\n",
    "    0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 5: 'bus',\n",
    "    7: 'truck', 9: 'traffic light', 11: 'stop sign', 15: 'cat', 16: 'dog'\n",
    "}\n",
    "for class_id, class_name in common_classes.items():\n",
    "    print(f\"   - {class_id}: {class_name}\")\n",
    "\n",
    "print(\"\\n3. Optimisations GPU:\")\n",
    "if DEVICE == 'cuda':\n",
    "    print(\"   ‚úÖ GPU activ√© avec optimisations:\")\n",
    "    print(\"   - Traitement par batch pour meilleure utilisation GPU\")\n",
    "    print(\"   - Nettoyage automatique de la m√©moire\")\n",
    "    print(\"   - Fusion des op√©rations (cudnn.benchmark)\")\n",
    "    print(\"   - Pr√©cision mixte possible (half precision)\")\n",
    "    \n",
    "    # Afficher l'utilisation m√©moire GPU\n",
    "    if torch.cuda.is_available():\n",
    "        memory_allocated = torch.cuda.memory_allocated() / (1024**3)\n",
    "        memory_reserved = torch.cuda.memory_reserved() / (1024**3)\n",
    "        print(f\"   - M√©moire GPU utilis√©e: {memory_allocated:.2f} GB\")\n",
    "        print(f\"   - M√©moire GPU r√©serv√©e: {memory_reserved:.2f} GB\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è GPU non disponible - optimisations CPU:\")\n",
    "    print(\"   - Threading pour lecture vid√©o\")\n",
    "    print(\"   - Optimisation m√©moire\")\n",
    "\n",
    "print(\"\\n4. Param√®tres recommand√©s:\")\n",
    "print(\"   - Confiance: 0.3-0.7 (plus bas = plus de d√©tections)\")\n",
    "print(\"   - IoU: 0.4-0.6 (plus bas = moins de doublons)\")\n",
    "if DEVICE == 'cuda':\n",
    "    print(\"   - Batch size: 4-8 pour GPU (selon m√©moire disponible)\")\n",
    "    print(\"   - Mod√®le: yolov8s ou yolov8m pour bon √©quilibre vitesse/pr√©cision sur GPU\")\n",
    "else:\n",
    "    print(\"   - Batch size: 1 pour CPU\")\n",
    "    print(\"   - Mod√®le: yolov8n pour vitesse maximale sur CPU\")\n",
    "\n",
    "print(\"\\n5. Conseils de performance:\")\n",
    "if DEVICE == 'cuda':\n",
    "    print(\"   üöÄ Avec GPU:\")\n",
    "    print(\"   - Utilisez des mod√®les plus grands (yolov8m, yolov8l) pour meilleure pr√©cision\")\n",
    "    print(\"   - Augmentez le batch size si vous avez assez de m√©moire GPU\")\n",
    "    print(\"   - Activez la pr√©cision mixte pour vitesse suppl√©mentaire\")\n",
    "else:\n",
    "    print(\"   üíª Avec CPU:\")\n",
    "    print(\"   - Utilisez yolov8n pour vitesse maximale\")\n",
    "    print(\"   - R√©duisez la r√©solution vid√©o si n√©cessaire\")\n",
    "    print(\"   - Consid√©rez traiter 1 image sur 2 pour vid√©os longues\")\n",
    "\n",
    "print(\"\\n‚ú® Vous pouvez modifier ces param√®tres dans les cellules pr√©c√©dentes et relancer le traitement.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52220ff2",
   "metadata": {},
   "source": [
    "## 10. Nettoyage et conclusion\n",
    "\n",
    "Nettoyage final et r√©sum√© des r√©sultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e5939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage final\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "print(\"üßπ Nettoyage termin√©.\")\n",
    "print(\"\\nüìã R√©sum√© du laboratoire YOLO:\")\n",
    "print(\"‚úÖ Mod√®le YOLO charg√© et configur√©\")\n",
    "print(\"‚úÖ Vid√©o trait√©e avec d√©tection d'objets\")\n",
    "print(\"‚úÖ Annotations ajout√©es avec bounding boxes\")\n",
    "print(\"‚úÖ Vid√©o annot√©e sauvegard√©e\")\n",
    "\n",
    "if VIDEO_PATH is not None:\n",
    "    output_path = Path(VIDEO_PATH).parent / f\"{Path(VIDEO_PATH).stem}_yolo_detected{Path(VIDEO_PATH).suffix}\"\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"\\nüéØ Votre vid√©o trait√©e est disponible √†: {output_path}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è La vid√©o de sortie n'a pas √©t√© cr√©√©e. V√©rifiez les erreurs ci-dessus.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è N'oubliez pas de sp√©cifier le chemin de votre vid√©o dans la cellule 4!\")\n",
    "\n",
    "print(\"\\nüöÄ Laboratoire YOLO termin√© avec succ√®s!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86525681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
