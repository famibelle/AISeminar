{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers torch\n",
    "# %pip install sentencepiece\n",
    "# %pip install sacremoses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab : Traduction automatique avec BERT\n",
    "\n",
    "Dans ce lab, vous allez découvrir comment utiliser un modèle pré-entraîné basé sur BERT pour effectuer une tâche de **traduction automatique**.\n",
    "\n",
    "Nous allons utiliser le modèle **MarianMT** de Hugging Face, qui est basé sur une architecture dérivée de BERT. Ce modèle est entraîné pour traduire des phrases entre plusieurs langues. Vous apprendrez à :\n",
    "1. Charger un modèle de traduction pré-entraîné.\n",
    "2. Traduire des phrases du **français** vers l'**anglais**.\n",
    "3. Expérimenter avec des phrases personnalisées pour observer les forces et les limites du modèle.\n",
    "\n",
    "### Objectifs du lab\n",
    "- Découvrir comment BERT peut être utilisé pour des tâches de traduction.\n",
    "- Tester des traductions automatiques sur des exemples interactifs.\n",
    "- Analyser les performances du modèle et identifier ses limites.\n",
    "\n",
    "### Modèle utilisé\n",
    "Nous utiliserons le modèle pré-entraîné \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 1 : Charger le modèle de traduction\n",
    "\n",
    "Dans cette section, nous allons :\n",
    "1. Charger le modèle pré-entraîné **Helsinki-NLP/opus-mt-fr-en**.\n",
    "2. Charger son tokenizer associé.\n",
    "\n",
    "Ce modèle est conçu pour traduire du français vers l'anglais. Les étudiants pourront tester la traduction sur plusieurs exemples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbb62085f264b3aa7ff808b40bf1303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f09a8b5250468cac018f73486a2626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece490b75ed840f3bdd86ec3ac8b1b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41836002ca6c450d93271d584db34bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a507d65c6e649da97730ba702b4a0bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 16:40:47.223263: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733240447.243561  200653 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733240447.249795  200653 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-03 16:40:47.270001: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73cbb1a2b50b4fcf807173309311dd8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5349e7874d7e4ac9ae1f599fd9eee9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé avec succès !\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Charger le tokenizer et le modèle MarianMT pour la traduction français-anglais\n",
    "model_name = \"Helsinki-NLP/opus-mt-fr-en\"  # Modèle de traduction français → anglais\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "print(\"Modèle chargé avec succès !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 2 : Traduire une phrase simple\n",
    "\n",
    "Le modèle est maintenant prêt ! Dans cette section, vous allez :\n",
    "1. Tester la traduction automatique sur une phrase simple en français.\n",
    "2. Observer la sortie produite par le modèle.\n",
    "\n",
    "### Exemple\n",
    "La phrase \"Bonjour, comment allez-vous aujourd'hui ?\" sera traduite en anglais. Essayez de modifier la phrase dans le code pour observer comment le modèle réagit à des phrases différentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original : Je suis en train de suivre une formation pour améliorer mes compétences.\n",
      "Traduction : I'm in the process of training to improve my skills.\n"
     ]
    }
   ],
   "source": [
    "# Phrase en français\n",
    "text1 = \"Bonjour, comment allez-vous aujourd'hui ?\"\n",
    "text2 = \"Je suis en train de suivre une formation pour améliorer mes compétences.\"\n",
    "text = text2\n",
    "\n",
    "# Tokenisation et encodage\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "# Générer la traduction\n",
    "outputs = model.generate(**inputs)\n",
    "\n",
    "# Décoder la traduction\n",
    "translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(f\"Texte original : {text}\")\n",
    "print(f\"Traduction : {translation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 3 : Tester vos propres phrases\n",
    "\n",
    "C'est maintenant à vous ! Entrez une phrase en français pour voir comment le modèle la traduit en anglais.\n",
    "\n",
    "### Exercice\n",
    "1. Essayez une phrase courte, comme \"Le soleil brille aujourd'hui.\"\n",
    "2. Essayez une phrase plus complexe ou idiomatique, comme \"Il pleut des cordes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte original : J'adore suivre les formations en IA proposées par AKABI\n",
      "Traduction : I love taking the AI courses offered by AKABI\n"
     ]
    }
   ],
   "source": [
    "# Tester vos propres phrases\n",
    "text = input(\"Entrez une phrase en français pour la traduction : \")\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "outputs = model.generate(**inputs)\n",
    "translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(f\"Texte original : {text}\")\n",
    "print(f\"Traduction : {translation}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
